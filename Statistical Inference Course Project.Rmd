---
title: "Statistical Inference Course Project"
author: "robertwcw"
date: "12/13/2020"
output: 
  html_document: 
    fig_caption: yes
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# Sys.setenv(TZ = "UTC")      # set global TZ to UTC for POSIXt class

.Rfliburl <- "https://raw.githubusercontent.com/robertwcw/Rflib/master"
source(file.path(.Rfliburl,"getRflib.R"),local = TRUE)
source(getRflib("is.defined.R"),local = TRUE)
source(getRflib("myplclust.R"),local = TRUE)
source(getRflib("strCap.R"),local = TRUE)
```

```{r init.local}
if (!requireNamespace("ggplot2",quietly = TRUE)) install.packages("ggplot2")
library(ggplot2)

par.def <- par(no.readonly = TRUE) 
```
&nbsp;

### Synopsis

This course work embarks on the objective to help us understand how simulation and Central Limit Theorem (CLT) are useful in statistical inference studies (resampling, confidence interval and hypothesis testing etc...) when the real-world data isn't readily available or ideal size of population data is constrained by the inevitable factors such as budget, time-limit and manpower etc. 

Simulation is handy for pumping up the sampling data size to enable a more normal distribution approach for statistical analysis. While CLT states that a sampling distribution of the statistic estimates for a variable, of sufficiently large sample size will approximate normal distribution regardless of the variable's distribution in the population, with the sampling estimates converging around the population estimates. In other words, when the simulated sampling means of a bootstrapped sample distribution converges around the population mean, we can deduce that the sample distributions are representative of the larger population distribution.
&nbsp;

```{r stat.simul}
# statistical simulation

n <- 40                 #number of exponential per sample 
B <- 1000               #bootstrap size
lambda <- 1/5           #observed rate of population
mu <- 1/lambda          #mean of population
siqma <- 1/lambda       #std-deviation of population
alpha <- 0.05           #alpha level for confidence interval test

# generate 1000 simulated distribution of 40 random exponential per sample
z <- matrix(nrow = B, ncol = n) 
for (i in 1:B) {z[i,] <- rexp(n, lambda)}; rm(i)

e <- NULL
e <- cbind(rexp(n*25, lambda), # 1000 sample random exponential distributed data
           apply(z, 1, mean))  # 1000 simulated means of each sample of 40 random exponential distributed data
e <- as.data.frame(e)
colnames(e) <- c("X_e", "X_mu")
```

### Statistical Simulation

This course work requires some simulated random exponential distribution data to show how CLT explains the skewed dataset (right-skewed in this case) will eventually fall into a normal distribution pattern when the amount of sampling data are increased to sufficient number. 

Specification of the dataset used in this demonstration, as follows:  

| Symbol | Description |  
|------------|-----------------------------------------------------------------|  
| $n = 40$ | Number of random exponential per sample |  
| $B = 1000$ | Number of simulation of sample of 40 random exponential each |  
| $\lambda = \frac {1} {5}$ | Theoretical rate |  
| $\mu = \frac {1} {\lambda}$ | Theoretical mean |  
| $\sigma  = \frac {1} {\lambda}$ | Theoretical standard deviation |  
| $X_e$ | Simulated dataset of 1000 random exponential |  
| $X_\mu$ | Simulated dataset of 1000 sample means of 40 random exponential each |  
&nbsp;

5-Number Summary of $X_\mu$  
```{r Xmu.summa}
summary(e$X_mu)
```
| Statistics | Estimated Values |
|------------|-----------------------------------------------------------------|
| $\bar{X}$ | `r round(mean(e$X_mu), 5)` |  
| $VAR(\bar{X})$ | `r round(var(e$X_mu), 5)` |  
| $\sigma_\bar{X}$ | `r round(sd(e$X_mu), 5)` |  
| $SE_\bar{X}$ | `r round(sd(e$X_mu)/sqrt(B), 5)` |  
&nbsp;

```{r plot.Xmu.boxplot}
# boxplot for bootstrapped mean of random exponential sample data 'X_mu'
b <- ggplot()
b <- b + geom_boxplot(data = e, mapping = aes(x = X_mu), 
                      outlier.colour = "darkorange",
                      size = 0.5,
                      varwidth = FALSE)
b <- b + labs(x = expression("X"[mu]), caption = "Figure-1")
print(b)  
```
&nbsp;

The boxplot graph in Figure-1 above shows normal distribution  us that the $X_\mu$ dataset is normal 


Mean of $X_\mu$, $\bar{X}$ = `r round(mean(e$X_mu), 5)`, is statistically equal to the theoretical mean $\mu$. Standard deviation $\sigma_\bar{X}$ = `r sd(e$X_mu)` and Variance $VAR(\bar{X})$ = `r var(e$X_mu)` explains that the estimated statistic of $X_\mu$ 

```{r plot.Xmu.hist}
# histogram for bootstrapped of 1000 mean of random exponential sample data 'X_mu'
h <- ggplot(data = e, mapping = aes(x = X_mu, y = ..density..)) 
h + geom_histogram(color = "black", fill = "white", bins = n) + 
    geom_density(alpha = 0.3, fill = "#FF6666", col = "red") + 
    geom_vline(aes(xintercept = mean(x = X_mu)), lty = 2, lwd = 0.6, col = "blue") +
    labs(x = expression("X"[mu]))

```


Summary of $X_e$ simulated random exponential dataset   
```{r Xe.summa}
summary(e$X_e)
```
$X_e$ mean $\mu$ is round(mean(e$X_e), 5) 
$\lambda$ 


```{r plot.hist.Xe}
# plot graph for the simulated data

# histogram for exponential distributed sample data 'X_e'
h <- ggplot(data = e, mapping = aes(x = X_e, y = ..density..)) 
h + geom_histogram(color = "black", fill = "white", binwidth = n/30) + 
    geom_density(alpha = 0.3, fill = "#FF6666", col = "red") +
    geom_vline(aes(xintercept = mean(x = X_e)), lty = 1, lwd = 0.6, col = "blue") +
    geom_vline(aes(xintercept = mu), lty = 2, lwd = 0.6, col = "green") +
    xlab(expression("X"[e]))


# boxplot for exponential distributed random sample data 'X_e'
b <- ggplot()
b <- b + geom_boxplot(data = e, mapping = aes(x = X_e), 
                      outlier.colour = "darkorange",
                      size = 0.5,
                      arwidth = FALSE)
b <- b + labs(x = expression("X"[e]))
print(b)





# t-test
CI_t <- mean(e$X_mu) + c(-1,1) * qt(1-alpha/2,NROW(e$X_mu)-1) * (sd(e$X_mu)/sqrt(length(e$X_mu)))
t_val <- (mean(e$X_mu) - mu)/(sd(e$X_mu)/sqrt(NROW(e$X_mu)))
p_val <- pt(q = abs(t_val), df = length(e$X_mu)-1, lower.tail=FALSE)*2

# z-test
CI_z <- mean(e$X_mu) + c(-1,1)*qnorm(1-alpha/2)*(sd(e$X_mu)/sqrt(length(e$X_mu)))
z_val <- (mean(e$X_mu) - mu)/(sd(e$X_mu)/sqrt(NROW(e$X_mu)))
p_val <- pnorm(abs(z_val), lower.tail = FALSE)*2

```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
